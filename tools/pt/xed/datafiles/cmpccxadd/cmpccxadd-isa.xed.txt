#BEGIN_LEGAL
#
#Copyright (c) 2023 Intel Corporation
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#  
#END_LEGAL
#
#
#
#    ***** GENERATED FILE -- DO NOT EDIT! *****
#    ***** GENERATED FILE -- DO NOT EDIT! *****
#    ***** GENERATED FILE -- DO NOT EDIT! *****
#
#
#
AVX_INSTRUCTIONS()::
# EMITTING CMPBEXADD (CMPBEXADD-128-1)
{
ICLASS:      CMPBEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE6 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPBEXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPBEXADD (CMPBEXADD-128-2)
{
ICLASS:      CMPBEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE6 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPBEXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPBXADD (CMPBXADD-128-1)
{
ICLASS:      CMPBXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE2 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPBXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPBXADD (CMPBXADD-128-2)
{
ICLASS:      CMPBXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE2 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPBXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPLEXADD (CMPLEXADD-128-1)
{
ICLASS:      CMPLEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xEE V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPLEXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPLEXADD (CMPLEXADD-128-2)
{
ICLASS:      CMPLEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xEE V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPLEXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPLXADD (CMPLXADD-128-1)
{
ICLASS:      CMPLXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xEC V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPLXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPLXADD (CMPLXADD-128-2)
{
ICLASS:      CMPLXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xEC V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPLXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNBEXADD (CMPNBEXADD-128-1)
{
ICLASS:      CMPNBEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE7 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNBEXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNBEXADD (CMPNBEXADD-128-2)
{
ICLASS:      CMPNBEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE7 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNBEXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNBXADD (CMPNBXADD-128-1)
{
ICLASS:      CMPNBXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE3 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNBXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNBXADD (CMPNBXADD-128-2)
{
ICLASS:      CMPNBXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE3 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNBXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNLEXADD (CMPNLEXADD-128-1)
{
ICLASS:      CMPNLEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xEF V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNLEXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNLEXADD (CMPNLEXADD-128-2)
{
ICLASS:      CMPNLEXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xEF V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNLEXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNLXADD (CMPNLXADD-128-1)
{
ICLASS:      CMPNLXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xED V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNLXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNLXADD (CMPNLXADD-128-2)
{
ICLASS:      CMPNLXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xED V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNLXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNOXADD (CMPNOXADD-128-1)
{
ICLASS:      CMPNOXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE1 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNOXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNOXADD (CMPNOXADD-128-2)
{
ICLASS:      CMPNOXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE1 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNOXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNPXADD (CMPNPXADD-128-1)
{
ICLASS:      CMPNPXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xEB V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNPXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNPXADD (CMPNPXADD-128-2)
{
ICLASS:      CMPNPXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xEB V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNPXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNSXADD (CMPNSXADD-128-1)
{
ICLASS:      CMPNSXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE9 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNSXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNSXADD (CMPNSXADD-128-2)
{
ICLASS:      CMPNSXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE9 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNSXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPNZXADD (CMPNZXADD-128-1)
{
ICLASS:      CMPNZXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE5 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPNZXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPNZXADD (CMPNZXADD-128-2)
{
ICLASS:      CMPNZXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE5 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPNZXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPOXADD (CMPOXADD-128-1)
{
ICLASS:      CMPOXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE0 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPOXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPOXADD (CMPOXADD-128-2)
{
ICLASS:      CMPOXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE0 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPOXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPPXADD (CMPPXADD-128-1)
{
ICLASS:      CMPPXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xEA V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPPXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPPXADD (CMPPXADD-128-2)
{
ICLASS:      CMPPXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xEA V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPPXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPSXADD (CMPSXADD-128-1)
{
ICLASS:      CMPSXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE8 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPSXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPSXADD (CMPSXADD-128-2)
{
ICLASS:      CMPSXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE8 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPSXADD_MEMu64_GPR64u64_GPR64u64
}


# EMITTING CMPZXADD (CMPZXADD-128-1)
{
ICLASS:      CMPZXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_4B 
PATTERN:    VV1 0xE4 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W0  mode64   
OPERANDS:    MEM0:rw:d:u32 REG0=VGPR32_R():rw:d:u32 REG1=VGPR32_N():r:d:u32
IFORM:       CMPZXADD_MEMu32_GPR32u32_GPR32u32
}


# EMITTING CMPZXADD (CMPZXADD-128-2)
{
ICLASS:      CMPZXADD
CPL:         3
CATEGORY:    VEX
EXTENSION:   CMPCCXADD
ISA_SET:     CMPCCXADD
EXCEPTIONS:     avx-type-14
REAL_OPCODE: Y
FLAGS:       MUST [  zf-mod  cf-mod  pf-mod  of-mod  sf-mod  af-mod  ]
ATTRIBUTES:  ATOMIC REQUIRES_ALIGNMENT_8B 
PATTERN:    VV1 0xE4 V66 V0F38 MOD[mm] MOD!=3 REG[rrr] RM[nnn]  MODRM()  VL128  W1  mode64   
OPERANDS:    MEM0:rw:q:u64 REG0=VGPR64_R():rw:q:u64 REG1=VGPR64_N():r:q:u64
IFORM:       CMPZXADD_MEMu64_GPR64u64_GPR64u64
}


