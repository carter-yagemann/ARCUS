#!/usr/bin/env python
#
# Copyright 2019 Carter Yagemann
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

from functools import reduce
import logging
import os
import re

import explore
import taint

import angr
from angr.exploration_techniques import ExplorationTechnique
import claripy
from cle.address_translator import AT
from networkx.algorithms.cycles import find_cycle
from networkx.exception import NetworkXNoCycle
import pyvex
from redis import Redis

log = logging.getLogger(__name__)


class CycleDB(object):
    """Allows sharing of data across sessions to, for example, avoid
    restressing the same loops."""

    def __init__(self):
        pass

    def set(self, key, value):
        """Set key to value."""
        pass

    def get(self, key):
        """Returns value for key, or None of key doesn't exist."""
        return None


class RedisDB(CycleDB):
    """Share data using a Redis database."""

    def __init__(self, connect_str):
        super(RedisDB, self).__init__()
        assert isinstance(connect_str, str)
        self.redis = None

        match = re.match("redis://([^:/]+):?([0-9]+)?/?([0-9]+)?", connect_str)

        if match is None:
            log.error("Invalid Redis connection string: %s" % connect_str)
        else:
            host, port, db = match.groups()
            if port is None:
                port = 6379
            if db is None:
                db = 0

            try:
                self.redis = Redis(host=host, port=port, db=db)
            except Exception as ex:
                log.error("Failed to connect to Redis: %s" % str(ex))
                self.redis = None

        if self.redis is None:
            log.warning("Continuing in offline mode")

    def set(self, key, value):
        """Set key to value."""
        if self.redis is None:
            return

        try:
            self.redis.set(key, value)
        except Exception as ex:
            log.error("Failed to set key in Redis: %s" % str(ex))

    def get(self, key):
        """Returns value for key, or None of key doesn't exist."""
        if self.redis is None:
            return None

        try:
            return self.redis.get(key)
        except Exception as ex:
            log.error("Failed to query Redis for key: %s" % str(ex))
            return None


class LoopBounds(ExplorationTechnique):
    """Searches for and stresses loops to find more bugs.

    Keyword Args:
    predecessors -- The list of states generated by Tracer.
    trace -- The list of basic block addresses in the original PT trace.
    options -- OptionParser dictionary.
    """

    def __init__(self, predecessors, trace, options):
        super(LoopBounds, self).__init__()
        self.orig_preds = predecessors
        self.predecessors = predecessors.copy()
        self.trace = trace
        self.matches = list()
        self._init_db(options.explore_db)

    def _init_db(self, connect):
        self.db = None

        if connect is None:
            pass
        elif not isinstance(connect, str):
            log.error("Connection must be a string")
        elif connect.startswith("redis://"):
            self.db = RedisDB(connect)
        else:
            log.error("Unsupported DB: %s" % connect)

        if self.db is None:
            log.warning("Continuing in offline mode")
            self.db = CycleDB()

    def _get_tmp_expr(self, tmp, pred_idx):
        """Gets the expression for tmp.

        Keyword Args:
        tmp - The tmp number to get.
        pred_idx - The index in self.orig_preds to check.

        Returns:
        Expression or None if it couldn't be found.
        """
        try:
            return self.orig_preds[pred_idx].scratch.tmp_expr(tmp)
        except (angr.errors.SimValueError, IndexError):
            return None

    def _get_all_cycles(self, graph):
        addrs = [pred.addr for pred in self.predecessors if not pred is None]
        cycles = list()
        hashes = set()
        for addr in addrs:
            try:
                cycle = [edge[0] for edge in find_cycle(graph, addr, None)]
            except NetworkXNoCycle:
                continue

            # xor hashing dedups cycles containing the same nodes in different orders
            hash = reduce(lambda a, b: a ^ b, cycle)
            if not hash in hashes:
                cycles.append(cycle)
                hashes.add(hash)

        return cycles

    def setup(self, simgr):
        """Select candidate loops to stress"""
        self.call_pushes_ret = self.project.arch.call_pushes_ret

        if not "missed" in simgr.stashes:
            simgr.populate("missed", [])
        simgr.drop(stash="active")

        loader = self.project.loader
        is_extern = (
            lambda addr: loader.find_object_containing(addr) == loader.extern_object
        )
        rotate = lambda l, n: l[-n:] + l[:-n]

        # find loops in the trace, excluding SimProcedures
        addrs = [pred.addr for pred in self.predecessors if not pred is None]
        if len(addrs) < 1:
            log.error("State has no predecessors")
            possible_cycles = list()
        else:
            graph = explore.simple_cfg(addrs)
            possible_cycles = self._get_all_cycles(graph)
        self.cycles = list()
        for cycle in possible_cycles:
            extern_addrs = [is_extern(addr) for addr in cycle]
            if not False in extern_addrs:
                continue
            else:
                # make sure cycle starts outside SimProcedures
                start_idx = extern_addrs.index(False)
                self.cycles.append(rotate(cycle, len(cycle) - start_idx))

        for cycle in self.cycles:
            assert not is_extern(cycle[0])

        # prune and prioritize cycles
        log.info("Cycles found:       %d" % len(self.cycles))
        self.cycles = [cycle for cycle in self.cycles if not self._filter_db(cycle)]
        log.info("After DB filtering: %d" % len(self.cycles))
        self.cycles = [cycle for cycle in self.cycles if not self._prune_cycle(cycle)]
        log.info("After pruning:      %d" % len(self.cycles))
        self.cycles.sort(key=self._prioritize_cycle)

        # queue up our first active state
        self._rewind(simgr, setup=True)

    def _is_tmp_load(self, stmt):
        """Is VEX IR statement a load from a non-constant address?"""
        if isinstance(stmt, pyvex.stmt.WrTmp):
            if isinstance(stmt.data, pyvex.expr.Load):
                if not isinstance(stmt.data.addr, pyvex.expr.Const):
                    return True
        return False

    def _is_tmp_store(self, stmt):
        """Is VEX IR statement a store to a non-constant address?"""
        if isinstance(stmt, pyvex.stmt.Store):
            if not isinstance(stmt.addr, pyvex.expr.Const):
                return True
        return False

    def _overflow_store_check(self, cycle):
        """We check for two write patterns: 1) monotonic step, 2) unique write address per iteration
        (heuristic from "Tupni: Automatic Reverse Engineering of Input Formats" by Weidong, et al.)"""
        loader = self.project.loader
        extern = loader.extern_object

        for addr in set(cycle):
            if loader.find_object_containing(addr) == extern:
                continue  # don't need to test simprocs

            matches = [hit for hit in enumerate(self.orig_preds) if hit[1].addr == addr]
            if len(matches) < 2:
                # there's no way we're going to see enough iterations to make a verdict
                continue

            for match in matches:
                num_iter = 0
                candidates = None
                block = match[1].block(addr)
                wrtmps = set(
                    [
                        stmt.addr.tmp
                        for stmt in block.vex.statements
                        if self._is_tmp_store(stmt)
                    ]
                )

                for idx, state in enumerate(self.orig_preds[match[0] :]):
                    if num_iter > 3:
                        break  # seen enough iterations
                    if not state.addr in cycle:
                        break  # exited loop
                    if state.addr != addr:
                        continue  # still in loop, but different basic block

                    # still in loop, at basic block we're testing, grab all non-constant store address tmps
                    num_iter += 1

                    if candidates is None:
                        # first visit to this basic block, create list of ASTs for each candidate
                        candidates = dict()
                        for tmp in wrtmps:
                            tmp_expr = self._get_tmp_expr(tmp, match[0] + idx + 1)
                            if not tmp_expr is None:
                                candidates[tmp] = [tmp_expr]
                    else:
                        # revisting this basic block, append new ASTs
                        for tmp in wrtmps:
                            if not tmp in candidates:
                                continue

                            store_addr = self._get_tmp_expr(tmp, match[0] + idx + 1)
                            if store_addr is None:
                                continue

                            candidates[tmp].append(store_addr)

                # check for write patterns
                solver = match[1].solver
                for tmp in candidates:
                    asts = candidates[tmp]
                    if len(asts) < 3:
                        continue  # not enough points to test

                    # check for monotonic write
                    if not solver.is_false((asts[1] - asts[0]) == (asts[2] - asts[1])):
                        # It is not obviously false that this store address changes monotonically.
                        # Note, it is still possible that it doesn't, but we don't want to invoke
                        # a full SAT solve, so we take the conservative approach of not pruning.
                        return True

                    if solver.is_true(
                        asts[0] != asts[1] and asts[1] != asts[2] and asts[2] != asts[0]
                    ):
                        # It is obviously true that this store address changes every time.
                        return True

        return False

    def _overflow_candidate(self, cycle):
        """Decide whether this cycle is an overflow candidate.

        Right now we only have one check.
        """
        if self._overflow_store_check(cycle):
            return True
        else:
            return False

    def _is_slow_cycle(self, cycle):
        """Checks if cycle invokes any known slow sim procedures"""
        slow_simprocs = [
            "realloc",
            "malloc",
            "calloc",
        ]

        for addr in cycle:
            if self.project.is_hooked(addr):
                hook = self.project.hooked_by(addr)
                if hook.display_name in slow_simprocs:
                    return True

        return False

    def _prioritize_cycle(self, cycle):
        """Higher score equals lower priority"""
        loader = self.project.loader
        is_extern = (
            lambda addr: loader.find_object_containing(addr) == loader.extern_object
        )
        score = 0

        if True in [is_extern(addr) for addr in cycle]:
            # cycles with SimProcedures tend to be slow
            score += 100000

        if self._is_slow_cycle(cycle):
            score += 100000

        score += len(cycle)

        return score

    def _hash_cycle(self, cycle):
        """Return a string hash uniquely identifying this cycle.

        Several tricks are used so that hashes are not impacted by ASLR, inserted
        simprocs, etc.
        """
        loader = self.project.loader

        # find object where cycle begins
        start_obj = loader.find_object_containing(cycle[0])
        start_obj_name = os.path.basename(start_obj.binary)
        if start_obj.is_main_bin:
            # main objects have their base VA appended onto the front of their name
            start_obj_name = start_obj_name.split("-", 1)[-1]

        # normalize addresses to account for ASLR, simprocs, etc.
        norm_cycle = list()
        extern_idx = 1
        for addr in cycle:
            if not start_obj.contains_addr(addr):
                norm_cycle.append(extern_idx)
                extern_idx += 1
            else:
                # use RVA instead of VA to normalize against ASLR
                norm_cycle.append(AT.from_va(addr, start_obj).to_rva())

        # calculate an AFL-like code coverage hash
        hash = 0
        for idx, addr in enumerate(norm_cycle):
            hash ^= addr << idx
        return "%s-%x" % (start_obj_name, hash)

    def _filter_db(self, cycle):
        """Should this cycle be skipped because another session already explored it?"""
        hash = self._hash_cycle(cycle)
        if not self.db.get(hash) is None:
            log.debug("Cycle %s already explored in another session, skipping" % hash)
            return True  # explored in another session

        return False

    def _prune_cycle(self, cycle):
        """Should this cycle be skipped for exploration?"""
        prune = True

        if self._overflow_candidate(cycle):
            prune = False

        if not prune:
            # add this hash to DB so future sessions won't explore it again
            self.db.set(self._hash_cycle(cycle), "")

        return prune

    def step(self, simgr, stash="active", **kwargs):
        simgr.drop(stash="missed")

        # this can happen if a detector plugin removes our active state because
        # further execution is no longer possible (e.g., symbolic IP)
        if len(simgr.stashes["active"]) < 1:
            log.warn("No more active states, rewinding")
            self._rewind(simgr, dump_matches=True)

        return simgr.step(stash=stash, **kwargs)

    def current_frame(self, state):
        """Return the starting address of the current stack frame, if known, otherwise None."""
        if not "frame_addrs" in state.deep:
            return None
        if len(state.deep["frame_addrs"]) < 1:
            return None
        return state.deep["frame_addrs"][-1]

    def is_prior_frame_symbolic(self, state, next_state):
        """Returns true if the last word in the prior stack frame is symbolic.

        Since the last thing on the frame is a return pointer for many architectures, this is
        a good indicator that a stack buffer overflow has manifest into a control-flow hijack.
        """
        word_size = self.project.arch.stack_change
        curr_frame = self.current_frame(state)

        # if we know the current stack frame's boundary, see if we're writting outside it
        # (i.e., stack smash)
        if not curr_frame is None:
            write_asts = taint.get_mem_accesses(
                state, next_state, loads=False, stores=True
            )
            for tmp, ast in write_asts:
                ret_corruption = claripy.And(
                    ast >= curr_frame, ast < curr_frame - (word_size * 128)
                )
                if next_state.solver.eval(ret_corruption):
                    return True
            return False

        # Due to the before_main libc simproc, main's stack frame address will be missing from
        # the list. A hacky workaround so we don't keep iterating until the *entire* stack is
        # corrupted is to check the next word after the base register, if the arch has one.
        bp_bv = state.registers.load(state.arch.bp_offset, size=state.arch.bits // 8)
        base = state.memory.load(bp_bv + word_size, size=abs(word_size))

        if state.solver.symbolic(base):
            return True

        return False

    def apply_sym_count_heuristic(self, state):
        """Called after exiting a cycle. Checks if the cycle was likely counting something in a memory
        location, in which case we symbolize it to give ourselves more flexibility moving forward.

        Conceptually, this is an implementation of the "loop-extended symbolic execution" technique
        proposed by Saxena et al. It enables us to exchange some soundness to efficiently encode all
        the possible ways we could have exited the prior cycle. E.g., even if we took the loop 10 times,
        if the number of iterations is stored in a variable, and we symbolize that intelligently, we
        can consider if we had exited at iterations 1 through 10 simultaneously, moving forward.
        """
        cycle = self.cycles[0]
        preds = self.predecessors + [state]
        preds_len = len(preds)

        in_cycle = False
        mem_writes = dict()
        for idx, pred in enumerate(preds[::-1]):
            ip_bv = pred.registers.load(pred.arch.ip_offset, size=pred.arch.bits // 8)
            if len(pred.solver.eval_upto(ip_bv, 2)) > 1:
                # symbolic IP with multiple values, skip it
                continue

            if not in_cycle and not pred.addr in cycle:
                # searching for the last state that was in the cycle
                continue
            elif not in_cycle and pred.addr in cycle:
                # we have reached the last predecessor that was inside the cycle
                in_cycle = True
            elif in_cycle and not pred.addr in cycle:
                # we're before the first state to enter the cycle, we're done
                break

            # this method should only be called on a state already outside the cycle, if this
            # assert fails, something is very wrong
            if idx == 0:
                log.warning("Cannot apply LESE heuristic while inside the loop")
                return

            # this predecessor was inside the target cycle, record what it wrote to memory
            succ = preds[preds_len - idx]
            assert succ.history.bbl_addrs[-1] == pred.addr
            write_asts = taint.get_mem_accesses(
                pred, succ, loads=False, stores=True, include_regs=True
            )
            # writes to symbolic addresses
            write_tmps = set([pair[0] for pair in write_asts if not pair[0] is None])
            # writes to constant addresses (including registers)
            write_cons = set([pair[1] for pair in write_asts if pair[0] is None])

            # we need to know the size of what was written to each address
            write_sizes_tmp = dict()  # addr tmp => stored value's result size
            write_sizes_con = dict()  # addr con => stored value's result size
            irsb = pred.block(pred.addr).vex
            for stmt in irsb.statements:
                if isinstance(stmt, pyvex.stmt.Store):
                    val_size = stmt.data.result_size(irsb.tyenv)
                    if (
                        isinstance(stmt.addr, pyvex.expr.Const)
                        and stmt.addr.con.value in write_cons
                    ):
                        # Store at constant address
                        write_sizes_con[stmt.addr.con.value] = val_size
                    elif stmt.addr.tmp in write_tmps:
                        # Store at tmp address
                        write_sizes_tmp[stmt.addr.tmp] = val_size
                elif isinstance(stmt, pyvex.stmt.Put) and stmt.offset in write_cons:
                    write_sizes_con[stmt.offset] = stmt.data.result_size(irsb.tyenv)

            # now we can update mem_writes with what was written where
            for tmp, ast in write_asts:
                write_addr = succ.solver.eval(ast)

                # filter out special registers
                if write_addr in [
                    state.arch.ip_offset,
                    state.arch.sp_offset,
                    state.arch.bp_offset,
                    state.arch.lr_offset,
                ]:
                    continue

                # we stash the value size as the last element of the array
                # to make sure all the BVs are the same size
                if not write_addr in mem_writes:
                    # retrieve stored value's size
                    if tmp is None:
                        val_size = write_sizes_con[write_addr]
                    else:
                        val_size = write_sizes_tmp[tmp]
                    mem_writes[write_addr] = [val_size]
                else:
                    val_size = mem_writes[write_addr][-1]

                if tmp is None and write_addr in succ.arch.register_names:
                    write_val = succ.registers.load(write_addr, size=val_size // 8)
                else:
                    write_val = succ.memory.load(
                        write_addr, size=val_size // 8, endness=succ.arch.memory_endness
                    )

                # we're iterating *backwards* through the trace, so we need to
                # *prepend* each write_val to its list
                mem_writes[write_addr].insert(0, write_val)

        # we have all the writes for every iteration of the cycle in mem_writes,
        # see if any of them look like counters
        for write_addr in mem_writes:
            write_vals = mem_writes[write_addr][:-1]  # last item is val size
            if len(write_vals) < 2:
                # too short
                continue

            if len(set(map(state.solver.eval, write_vals))) < 2:
                # value never changed
                continue

            # check if value always increases
            val_inc = True
            for idx, curr_val in enumerate(write_vals[1:]):
                prev_val = write_vals[idx]
                if state.solver.is_false(prev_val <= curr_val):
                    val_inc = False
                    break

            if val_inc:
                # this value may be counting something, make it symbolically
                # represent all prior values
                val_bits = write_vals[0].size()
                if write_addr in state.arch.register_names:
                    reg_name = state.arch.register_names[write_addr]
                    log.info("Symbolizing %d bits in %s" % (val_bits, reg_name))
                else:
                    log.info(
                        "Symbolizing %d bits at address %#x" % (val_bits, write_addr)
                    )
                new_sym = state.solver.BVS("lese", val_bits)
                con = state.solver.Or(*[new_sym == val for val in write_vals])
                state.memory.store(
                    write_addr, new_sym, endness=state.arch.memory_endness
                )
                state.add_constraints(con)

    def step_state(self, simgr, state, **kwargs):
        # maintain the predecessors list
        self.predecessors.append(state)

        # describe where we currently are in exploration
        loader = self.project.loader
        ctx_id = len(self.matches) // 2 + 1
        if loader.find_object_containing(state.addr):
            log.info(
                "Loop Explorer: (%d.%d) (%d) %s",
                len(self.cycles),
                ctx_id,
                state.globals["wander_budget"],
                loader.describe_addr(state.addr),
            )
        else:
            log.info(
                "Loop Explorer: (%d.%d) (%d) %#x",
                len(self.cycles),
                ctx_id,
                state.globals["wander_budget"],
                state.addr,
            )

        succs = {"active": [], "missed": []}

        # get all satisfiable candidates, otherwise we cannot continue and should rewind
        try:
            candidates = [
                succ
                for succ in state.step().all_successors
                if succ.solver.satisfiable()
            ]
        except Exception as ex:
            log.debug("Cannot step: %s" % str(ex))
            candidates = []

        # figure out where to go next (which state to set as active)
        if len(self.cycles) > 0 and state.addr in self.cycles[0]:
            # current state is inside the target cycle,
            # figure out what the next address should be to follow the cycle
            if state.addr == self.cycles[0][-1]:
                next_addr = self.cycles[0][0]
            else:
                next_addr = self.cycles[0][self.cycles[0].index(state.addr) + 1]

            # should we try to stay in the cycle or exit it?
            if self.ovf_frame is None:
                # try to stay in the loop by picking a successor that follows the cycle
                for succ in candidates:
                    if succ.addr == next_addr:
                        succs["active"] = [succ]
                    else:
                        succs["missed"].append(succ)

                exited_cycle = False

                if len(succs["active"]) == 0 and len(succs["missed"]) > 0:
                    # we're being forced to exit the loop...
                    log.debug("Cannot follow cycle anymore")
                    succs["active"].append(succs["missed"][0])
                    succs["missed"] = succs["missed"][1:]
                    exited_cycle = True

                elif self.call_pushes_ret and len(succs["active"]) > 0:
                    # there's a successor that follows the cycle and this is a return-on-stack
                    # kind of machine arch, check if its stack is corrupt
                    oob_frame_write = self.is_prior_frame_symbolic(
                        state, succs["active"][0]
                    )
                    if oob_frame_write:
                        # we've likely corrupted the prior stack frame, set exited_cycle so
                        # in future steps we know to try to exit the loop
                        log.info(
                            "May have corrupted prior frame, trying to leave cycle"
                        )
                        exited_cycle = True

                if exited_cycle:
                    # Note what frame we're currently in because we want to wander
                    # at least until the current function is finished. Setting this also
                    # signals to future steps that if we're still in the loop, we want out.
                    self.ovf_frame = (
                        self.current_frame(state),
                        len(state.deep["frame_addrs"]) - 1,
                    )

            if not self.ovf_frame is None:
                # we want to be outside the loop, but we're still in it...
                # search for an exit
                possible_exits = set([b for a, b in self.exits if a == state.addr])
                found_exit = False

                if len(possible_exits) > 0:
                    for succ in candidates:
                        if succ.addr in possible_exits:
                            log.debug(
                                "Found known exit: %#x => %#x" % (state.addr, succ.addr)
                            )
                            succs["active"] = [succ]
                            found_exit = True
                            break

                if not found_exit and len(succs["missed"]) > 0:
                    # we couldn't find an exit that we know about, try anything that
                    # doesn't follow the cycle
                    succs["active"] = [succs["missed"][0]]
                    succs["missed"] = succs["missed"][1:]

        elif len(candidates) > 0:
            # not currently inside the target loop, we're just wandering at this point
            # to see if a bug pops up
            succs["active"] = [candidates[0]]
            succs["missed"] = candidates[1:]

            if not self.sym_cnt_heuristic:
                # check if the loop we exited may have done any "counting" and if so
                # symbolize such values to give us more flexibility moving forward
                self.apply_sym_count_heuristic(succs["active"][0])
                # we only need to apply this once per run
                self.sym_cnt_heuristic = True

            # check if we're expecting a corrupted frame
            curr_frame_idx = len(state.deep["frame_addrs"]) - 1
            if not self.ovf_frame is None:
                ovf_frame_addr, ovf_frame_idx = self.ovf_frame
            else:
                ovf_frame_addr, ovf_frame_idx = (None, None)

            if (
                ovf_frame_addr is None
                or curr_frame_idx < ovf_frame_idx
                or state.deep["frame_addrs"][ovf_frame_idx] != ovf_frame_addr
            ):
                # we're wandering freely at this point and not expecting
                # a corrupted return pointer
                self.ovf_frame = None
                succs["active"][0].globals["wander_budget"] -= 1

            if succs["active"][0].globals["wander_budget"] < 1:
                # we've hit our wander limit, it's time to give up and rewind
                log.warning("Wander budget exhausted, ending run")
                succs["missed"].append(succs["active"][0])
                succs["active"] = list()

        # if we absolutely could not find a successor state, we're done with this run
        # and it's time to rewind
        if len(succs["active"]) == 0:
            log.debug("Rewinding")
            self._rewind(simgr)
            if len(simgr.stashes["active"]) > 0:
                succs["active"] = [simgr.stashes["active"][0]]

        return succs

    def _find_exits(self, trace, cycle):
        """Given a list of basic block addresses (trace) and a cycle from _rewind, determine
        what are the likely edges to exit this cycle."""
        exits = list()
        in_cycle = False

        for idx, addr in enumerate(trace):
            if addr in cycle:
                in_cycle = True
            elif not addr in cycle and in_cycle:
                in_cycle = False
                exits.append([trace[idx - 1], addr])

        log.debug(
            "Found exits: %s" % ", ".join(["[%#x,%#x]" % (a, b) for a, b in exits])
        )
        return exits

    def _rewind(self, simgr, setup=False, dump_matches=False):
        """Queues up the next candidate by rewinding and then setting it as active"""
        simgr.drop(stash="active")

        # sometimes we may want to dump our remaining matches and move on to the next
        # cycle (for example, if we've already found the bugs we were expecting)
        if dump_matches:
            self.matches = list()

        # we stress every loop in every available context
        while len(self.matches) == 0 and len(self.cycles) > 0:
            if not setup:
                self.cycles.pop(0)
                setup = False

            if len(self.cycles) < 1:
                log.debug("No more cycles to explore")
                return
            else:
                self.matches = explore.find_all_preds(
                    self.orig_preds.copy(), self.cycles[0][0]
                )
                self.exits = self._find_exits(
                    [state.addr for state in self.orig_preds], self.cycles[0]
                )

        if len(self.matches) < 1:
            log.info("Nothing to explore")
            return

        # setup exploration
        active, preds = self.matches.pop(0)
        # once we exit the cycle, we don't want to keep wandering forever waiting for
        # a bug to appear, so we set a budget for how long we'll wander before rewinding
        active.globals["wander_budget"] = 150
        # if we believe a return pointer has been overwritten, we don't want to start
        # decrementing the wander budget until *after* the current frame has returned
        self.ovf_frame = None
        # we have not applied the symbolic count heuristic (i.e., LESE) to this run yet
        self.sym_cnt_heuristic = False
        # setup stash and predecessors
        simgr.stashes["active"] = [active]
        self.predecessors = preds

    def complete(self, simgr):
        """Returns True when there's nothing left to explore"""
        return len(self.matches) < 1 and len(self.cycles) < 1


explorer = LoopBounds
